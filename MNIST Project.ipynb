{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which reads labels when fed file path and returns 1d array\n",
    "def labelss(filepath):\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            labels = []\n",
    "            \n",
    "            #Saves variables that arent bytes for labels\n",
    "            magicNum = (int.from_bytes(f.read(4), \"big\"))\n",
    "            noLabels = (int.from_bytes(f.read(4), \"big\"))\n",
    "            \n",
    "            #for loop for range, 60,000/10,000\n",
    "            for i in range(noLabels):\n",
    "                #Reads byte at a time and appends to list\n",
    "                labels.append((int.from_bytes(f.read(1), \"big\")))\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append vs extend:  https://stackoverflow.com/questions/252703/difference-between-append-vs-extend-list-methods-in-python\n",
    "\n",
    "#function which reads images when fed file path and returns 2d array\n",
    "def imagess(filepath):\n",
    "    with gzip.open(filepath, 'rb') as f:     \n",
    "        \n",
    "        #Save variables that are not image bytes\n",
    "        magicNum = (int.from_bytes(f.read(4), \"big\"))\n",
    "        noImages = (int.from_bytes(f.read(4), \"big\"))\n",
    "        noRow = (int.from_bytes(f.read(4), \"big\"))\n",
    "        noCol = (int.from_bytes(f.read(4), \"big\"))\n",
    "                \n",
    "        images = []\n",
    "        \n",
    "        for i in range(noImages):\n",
    "            row = []\n",
    "            for k in range(noRow):\n",
    "                col = []\n",
    "                for j in range(noCol):\n",
    "                    col.append(int.from_bytes(f.read(1), \"big\"))\n",
    "                #extend used here to add each 28 bytes to 1d array of length [1,2,3,4,5,6]\n",
    "                #vs append which would create a 2d array [[1,2,3],[4,5,6]]\n",
    "                row.extend(col)\n",
    "            images.append(row)     \n",
    "            \n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls function and feeds it a directory to read file from\n",
    "train_Labels = labelss(\"C:\\\\Users\\\\Damian Curran\\\\Desktop\\\\mnist\\\\train-labels.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls function and feeds it a directory to read file from\n",
    "train_Images = imagess(\"C:\\\\Users\\\\Damian Curran\\\\Desktop\\\\mnist\\\\train-images.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9]\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#np.eye: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.eye.html\n",
    "#one hot encoding explanation: https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    "\n",
    "#setting depth of one_hot, we have 10 labels\n",
    "depth = 10\n",
    "\n",
    "#converts to one_hot vector using numpy\n",
    "train_Labels_hot = np.eye(depth)[train_Labels_notHot]\n",
    "\n",
    "#show effects of one_hot\n",
    "print(train_Labels_notHot[0:5])\n",
    "print(train_Labels_hot[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are changed to pythons liking to more accurately adjust towards the correct output\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#this takes as many values of size 784, it is size 784 because we feed it an image array which is length 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "#stores the unscaled matrix multiplication into model\n",
    "model = (x @ w) + b\n",
    "\n",
    "#this will hold the ouputs, the 10 different label types [0,1,2,3,4,5,6,7,8,9]\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#this represents the index of label types\n",
    "y_int = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "#saves normalized data into y_pred\n",
    "y_pred = tf.nn.softmax(model)\n",
    "\n",
    "#gets largest index e.g [1,3,2] largest index = 1\n",
    "#index representation   [0,1,2]\n",
    "y_pred_int = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "#can seperate out softmax and cross_entropy\n",
    "#using this function is more accurate, and less lines of code\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=model,\n",
    "                                                        labels=y)\n",
    "#computes the mean of elements across a tensor\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#tf.equal returns bools(true, false) and stores in correct_prediction\n",
    "correct = tf.equal(y_pred_int, y_int)\n",
    "\n",
    "#we then cast correct_prediction to a float which returns 0 if false and 1 if true \n",
    "#we then use reduce_mean function to find avrage\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "#this will be used later to get the predicted int value of our labels\n",
    "y_value = y_pred_int\n",
    "\n",
    "#every tensorflow program uses an optimizer, the most used one is GradientDescent\n",
    "#https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00001)\n",
    "train = optimizer.minimize(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
